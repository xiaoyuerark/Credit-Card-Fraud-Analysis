{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using logistic regression and knn to predict credit card fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 999)\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from statsmodels.api import add_constant\n",
    "\n",
    "from statsmodels.regression.linear_model import RegressionResults\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Note --  Requires sklearn version .18 or higher  \n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from collections import Counter\n",
    "sns.set(style=\"ticks\")\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "matplotlib.rcParams['figure.figsize'] = (13.0, 6.0)\n",
    "\n",
    "assert(sys.version_info.major==3),print(sys.version)\n",
    "# Python 3 or higher is required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (1): Load in the Cancer data and conduct basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_cell_guid": "71cf9d69-032c-4e3c-aae4-fff3f2c4be81",
    "_uuid": "6793167d7f8c9745505b6b4c0fc537e26f0c95cb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "ce2f144b82a15d2f214af1d81c59458a272c6fd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>-0.551600</td>\n",
       "      <td>-0.617801</td>\n",
       "      <td>-0.991390</td>\n",
       "      <td>-0.311169</td>\n",
       "      <td>1.468177</td>\n",
       "      <td>-0.470401</td>\n",
       "      <td>0.207971</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>0.403993</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>1.612727</td>\n",
       "      <td>1.065235</td>\n",
       "      <td>0.489095</td>\n",
       "      <td>-0.143772</td>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.463917</td>\n",
       "      <td>-0.114805</td>\n",
       "      <td>-0.183361</td>\n",
       "      <td>-0.145783</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>0.624501</td>\n",
       "      <td>0.066084</td>\n",
       "      <td>0.717293</td>\n",
       "      <td>-0.165946</td>\n",
       "      <td>2.345865</td>\n",
       "      <td>-2.890083</td>\n",
       "      <td>1.109969</td>\n",
       "      <td>-0.121359</td>\n",
       "      <td>-2.261857</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>-0.226487</td>\n",
       "      <td>0.178228</td>\n",
       "      <td>0.507757</td>\n",
       "      <td>-0.287924</td>\n",
       "      <td>-0.631418</td>\n",
       "      <td>-1.059647</td>\n",
       "      <td>-0.684093</td>\n",
       "      <td>1.965775</td>\n",
       "      <td>-1.232622</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>-0.822843</td>\n",
       "      <td>0.538196</td>\n",
       "      <td>1.345852</td>\n",
       "      <td>-1.119670</td>\n",
       "      <td>0.175121</td>\n",
       "      <td>-0.451449</td>\n",
       "      <td>-0.237033</td>\n",
       "      <td>-0.038195</td>\n",
       "      <td>0.803487</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28  Amount  Class\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787  0.090794 -0.551600 -0.617801 -0.991390 -0.311169  1.468177 -0.470401  0.207971  0.025791  0.403993  0.251412 -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0\n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425 -0.166974  1.612727  1.065235  0.489095 -0.143772  0.635558  0.463917 -0.114805 -0.183361 -0.145783 -0.069083 -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      0\n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654  0.207643  0.624501  0.066084  0.717293 -0.165946  2.345865 -2.890083  1.109969 -0.121359 -2.261857  0.524980  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0\n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024 -0.054952 -0.226487  0.178228  0.507757 -0.287924 -0.631418 -1.059647 -0.684093  1.965775 -1.232622 -0.208038 -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0\n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739  0.753074 -0.822843  0.538196  1.345852 -1.119670  0.175121 -0.451449 -0.237033 -0.038195  0.803487  0.408542 -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show top 5 lines by default\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>1.693438e-15</td>\n",
       "      <td>1.479045e-15</td>\n",
       "      <td>3.482336e-15</td>\n",
       "      <td>1.392007e-15</td>\n",
       "      <td>-7.528491e-16</td>\n",
       "      <td>4.328772e-16</td>\n",
       "      <td>9.049732e-16</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>1.088850e+00</td>\n",
       "      <td>1.020713e+00</td>\n",
       "      <td>9.992014e-01</td>\n",
       "      <td>9.952742e-01</td>\n",
       "      <td>9.585956e-01</td>\n",
       "      <td>9.153160e-01</td>\n",
       "      <td>8.762529e-01</td>\n",
       "      <td>8.493371e-01</td>\n",
       "      <td>8.381762e-01</td>\n",
       "      <td>8.140405e-01</td>\n",
       "      <td>7.709250e-01</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>-2.458826e+01</td>\n",
       "      <td>-4.797473e+00</td>\n",
       "      <td>-1.868371e+01</td>\n",
       "      <td>-5.791881e+00</td>\n",
       "      <td>-1.921433e+01</td>\n",
       "      <td>-4.498945e+00</td>\n",
       "      <td>-1.412985e+01</td>\n",
       "      <td>-2.516280e+01</td>\n",
       "      <td>-9.498746e+00</td>\n",
       "      <td>-7.213527e+00</td>\n",
       "      <td>-5.449772e+01</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>-5.354257e-01</td>\n",
       "      <td>-7.624942e-01</td>\n",
       "      <td>-4.055715e-01</td>\n",
       "      <td>-6.485393e-01</td>\n",
       "      <td>-4.255740e-01</td>\n",
       "      <td>-5.828843e-01</td>\n",
       "      <td>-4.680368e-01</td>\n",
       "      <td>-4.837483e-01</td>\n",
       "      <td>-4.988498e-01</td>\n",
       "      <td>-4.562989e-01</td>\n",
       "      <td>-2.117214e-01</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>-9.291738e-02</td>\n",
       "      <td>-3.275735e-02</td>\n",
       "      <td>1.400326e-01</td>\n",
       "      <td>-1.356806e-02</td>\n",
       "      <td>5.060132e-02</td>\n",
       "      <td>4.807155e-02</td>\n",
       "      <td>6.641332e-02</td>\n",
       "      <td>-6.567575e-02</td>\n",
       "      <td>-3.636312e-03</td>\n",
       "      <td>3.734823e-03</td>\n",
       "      <td>-6.248109e-02</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>4.539234e-01</td>\n",
       "      <td>7.395934e-01</td>\n",
       "      <td>6.182380e-01</td>\n",
       "      <td>6.625050e-01</td>\n",
       "      <td>4.931498e-01</td>\n",
       "      <td>6.488208e-01</td>\n",
       "      <td>5.232963e-01</td>\n",
       "      <td>3.996750e-01</td>\n",
       "      <td>5.008067e-01</td>\n",
       "      <td>4.589494e-01</td>\n",
       "      <td>1.330408e-01</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>2.374514e+01</td>\n",
       "      <td>1.201891e+01</td>\n",
       "      <td>7.848392e+00</td>\n",
       "      <td>7.126883e+00</td>\n",
       "      <td>1.052677e+01</td>\n",
       "      <td>8.877742e+00</td>\n",
       "      <td>1.731511e+01</td>\n",
       "      <td>9.253526e+00</td>\n",
       "      <td>5.041069e+00</td>\n",
       "      <td>5.591971e+00</td>\n",
       "      <td>3.942090e+01</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4            V5            V6            V7            V8            V9           V10           V11           V12           V13           V14           V15           V16           V17           V18           V19           V20           V21           V22           V23           V24           V25           V26           V27           V28         Amount          Class\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000  284807.000000\n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15 -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15  1.768627e-15  9.170318e-16 -1.810658e-15  1.693438e-15  1.479045e-15  3.482336e-15  1.392007e-15 -7.528491e-16  4.328772e-16  9.049732e-16  5.085503e-16  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15  1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619       0.001727\n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  1.088850e+00  1.020713e+00  9.992014e-01  9.952742e-01  9.585956e-01  9.153160e-01  8.762529e-01  8.493371e-01  8.381762e-01  8.140405e-01  7.709250e-01  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109       0.041527\n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01 -2.458826e+01 -4.797473e+00 -1.868371e+01 -5.791881e+00 -1.921433e+01 -4.498945e+00 -1.412985e+01 -2.516280e+01 -9.498746e+00 -7.213527e+00 -5.449772e+01 -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000       0.000000\n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01 -5.354257e-01 -7.624942e-01 -4.055715e-01 -6.485393e-01 -4.255740e-01 -5.828843e-01 -4.680368e-01 -4.837483e-01 -4.988498e-01 -4.562989e-01 -2.117214e-01 -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000       0.000000\n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02 -9.291738e-02 -3.275735e-02  1.400326e-01 -1.356806e-02  5.060132e-02  4.807155e-02  6.641332e-02 -6.567575e-02 -3.636312e-03  3.734823e-03 -6.248109e-02 -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000       0.000000\n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  4.539234e-01  7.395934e-01  6.182380e-01  6.625050e-01  4.931498e-01  6.488208e-01  5.232963e-01  3.996750e-01  5.008067e-01  4.589494e-01  1.330408e-01  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000       0.000000\n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  2.374514e+01  1.201891e+01  7.848392e+00  7.126883e+00  1.052677e+01  8.877742e+00  1.731511e+01  9.253526e+00  5.041069e+00  5.591971e+00  3.942090e+01  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000       1.000000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Normalize the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "fd43bf1ac4cb01067fb9404d18b728f52fad0073",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>V11</th>\n",
       "      <th>V12</th>\n",
       "      <th>V13</th>\n",
       "      <th>V14</th>\n",
       "      <th>V15</th>\n",
       "      <th>V16</th>\n",
       "      <th>V17</th>\n",
       "      <th>V18</th>\n",
       "      <th>V19</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.766490</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>0.763439</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.475312</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.252484</td>\n",
       "      <td>0.680908</td>\n",
       "      <td>0.371591</td>\n",
       "      <td>0.635591</td>\n",
       "      <td>0.446084</td>\n",
       "      <td>0.434392</td>\n",
       "      <td>0.737173</td>\n",
       "      <td>0.655066</td>\n",
       "      <td>0.594863</td>\n",
       "      <td>0.582942</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.522992</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.391253</td>\n",
       "      <td>0.585122</td>\n",
       "      <td>0.394557</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.770067</td>\n",
       "      <td>0.840298</td>\n",
       "      <td>0.271796</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.262192</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>0.505267</td>\n",
       "      <td>0.381188</td>\n",
       "      <td>0.744342</td>\n",
       "      <td>0.486190</td>\n",
       "      <td>0.641219</td>\n",
       "      <td>0.383840</td>\n",
       "      <td>0.464105</td>\n",
       "      <td>0.727794</td>\n",
       "      <td>0.640681</td>\n",
       "      <td>0.551930</td>\n",
       "      <td>0.579530</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.480237</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.336440</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.446013</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.868141</td>\n",
       "      <td>0.268766</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.513018</td>\n",
       "      <td>0.322422</td>\n",
       "      <td>0.706683</td>\n",
       "      <td>0.503854</td>\n",
       "      <td>0.640473</td>\n",
       "      <td>0.511697</td>\n",
       "      <td>0.357443</td>\n",
       "      <td>0.763381</td>\n",
       "      <td>0.644945</td>\n",
       "      <td>0.386683</td>\n",
       "      <td>0.585855</td>\n",
       "      <td>0.565477</td>\n",
       "      <td>0.546030</td>\n",
       "      <td>0.678939</td>\n",
       "      <td>0.289354</td>\n",
       "      <td>0.559515</td>\n",
       "      <td>0.402727</td>\n",
       "      <td>0.415489</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.941878</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.765647</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>0.507585</td>\n",
       "      <td>0.271817</td>\n",
       "      <td>0.710910</td>\n",
       "      <td>0.487635</td>\n",
       "      <td>0.636372</td>\n",
       "      <td>0.289124</td>\n",
       "      <td>0.415653</td>\n",
       "      <td>0.711253</td>\n",
       "      <td>0.788492</td>\n",
       "      <td>0.467058</td>\n",
       "      <td>0.578050</td>\n",
       "      <td>0.559734</td>\n",
       "      <td>0.510277</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.223826</td>\n",
       "      <td>0.614245</td>\n",
       "      <td>0.389197</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.776520</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>0.269796</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.263984</td>\n",
       "      <td>0.268968</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>0.524303</td>\n",
       "      <td>0.236355</td>\n",
       "      <td>0.724477</td>\n",
       "      <td>0.552509</td>\n",
       "      <td>0.608406</td>\n",
       "      <td>0.349419</td>\n",
       "      <td>0.434995</td>\n",
       "      <td>0.724243</td>\n",
       "      <td>0.650665</td>\n",
       "      <td>0.626060</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.561327</td>\n",
       "      <td>0.547271</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.401270</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>0.507497</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time        V1        V2        V3        V4        V5        V6        V7        V8        V9       V10       V11       V12       V13       V14       V15       V16       V17       V18       V19       V20       V21       V22       V23       V24       V25       V26       V27       V28    Amount  Class\n",
       "0  0.000000  0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815  0.786444  0.475312  0.510600  0.252484  0.680908  0.371591  0.635591  0.446084  0.434392  0.737173  0.655066  0.594863  0.582942  0.561184  0.522992  0.663793  0.391253  0.585122  0.394557  0.418976  0.312697  0.005824      0\n",
       "1  0.000000  0.978542  0.770067  0.840298  0.271796  0.766120  0.262192  0.264875  0.786298  0.453981  0.505267  0.381188  0.744342  0.486190  0.641219  0.383840  0.464105  0.727794  0.640681  0.551930  0.579530  0.557840  0.480237  0.666938  0.336440  0.587290  0.446013  0.416345  0.313423  0.000105      0\n",
       "2  0.000006  0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177  0.788042  0.410603  0.513018  0.322422  0.706683  0.503854  0.640473  0.511697  0.357443  0.763381  0.644945  0.386683  0.585855  0.565477  0.546030  0.678939  0.289354  0.559515  0.402727  0.415489  0.311911  0.014739      0\n",
       "3  0.000006  0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803  0.789434  0.414999  0.507585  0.271817  0.710910  0.487635  0.636372  0.289124  0.415653  0.711253  0.788492  0.467058  0.578050  0.559734  0.510277  0.662607  0.223826  0.614245  0.389197  0.417669  0.314371  0.004807      0\n",
       "4  0.000012  0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968  0.782484  0.490950  0.524303  0.236355  0.724477  0.552509  0.608406  0.349419  0.434995  0.724243  0.650665  0.626060  0.584615  0.561327  0.547271  0.663392  0.401270  0.566343  0.507497  0.420561  0.317490  0.002724      0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    num = x - np.min(x)\n",
    "    denom = np.max(x) - np.min(x)\n",
    "    return (num / denom)\n",
    "\n",
    "df.iloc[:, 0:30] = normalize(df.iloc[:, 0:30])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "_uuid": "e61b5260bafcfbbc3a90b4704fb21c9ba3500642"
   },
   "outputs": [],
   "source": [
    "def split_data(data, train_size=.7):\n",
    "    # creat a list of the indexes of fraud&nonfraud behaviour data\n",
    "    index1 = data[data['Class']==1].index.values\n",
    "    index0 = data[data['Class']==0].index.values\n",
    "    # Determine the number of observations we have in each data set:\n",
    "    length1 = len(index1)\n",
    "    length0 = len(index0)\n",
    "    \n",
    "    # Use numpy's random.shuffle() function to randomly shuffle over our index:\n",
    "    np.random.shuffle(index1)\n",
    "    np.random.shuffle(index0)\n",
    "    \n",
    "    # Create a list for the first 70% of the shuffled indices and set to training: \n",
    "    train_indices1 = index1[0:int(length1 * train_size)]\n",
    "    train_indices0 = index0[0:int(length0 * train_size)]\n",
    "    train_indices = np.append(train_indices1, train_indices0, axis = 0)\n",
    "    \n",
    "    # Create a list for the remaining 30% of the shuffled indices and set to testing:\n",
    "    test_indices1 = index1[int(length1 * train_size):]\n",
    "    test_indices0 = index0[int(length0 * train_size):]\n",
    "    test_indices = np.append(test_indices1,test_indices0, axis = 0)\n",
    "    \n",
    "    # Use the list of training indices to find the corresponding data entries:\n",
    "    train = data.iloc[train_indices]\n",
    "    # Use the list of testing indices to find the corresponding data entries:\n",
    "    test = data.iloc[test_indices]\n",
    "    \n",
    "    # Return two dataframes, one with the testing data and one with the training data:\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the function to split the actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "02f299e179461304a0642850b501374aa9926a02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(199364, 31)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train,df_test  = split_data(df)\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = df_train.loc[:, df_train.columns != 'Class'] #Your code goes here\n",
    "X_test  = df_test.loc[:, df_test.columns != 'Class']\n",
    "\n",
    "X_train_np = X_train.values # This is to create a numpy array version of the training and testing set.\n",
    "X_test_np  = X_test.values\n",
    "y_train = df_train['Class'].values\n",
    "y_test = df_test['Class'].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Using one single predictor to fit a Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the training/testing dataset as before and create our logistic regression objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use one single predictor variable, `V 10` and fit a linear regression model to it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "_uuid": "0fd71daae0ef1f27401b7df8f25e41f1ecc29b4a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th>  <td>   0.046</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.046</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   9715.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 15 Mar 2018</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:32:54</td>     <th>  Log-Likelihood:    </th> <td>3.5623e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>199364</td>      <th>  AIC:               </th> <td>-7.125e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>199362</td>      <th>  BIC:               </th> <td>-7.124e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.2040</td> <td>    0.002</td> <td>   99.309</td> <td> 0.000</td> <td>    0.200</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>V10</th>   <td>   -0.3976</td> <td>    0.004</td> <td>  -98.566</td> <td> 0.000</td> <td>   -0.406</td> <td>   -0.390</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>455375.505</td> <th>  Durbin-Watson:     </th>    <td>   0.095</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2328850286.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td>22.492</td>   <th>  Prob(JB):          </th>    <td>    0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>530.570</td>  <th>  Cond. No.          </th>    <td>    56.0</td>   \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.046\n",
       "Model:                            OLS   Adj. R-squared:                  0.046\n",
       "Method:                 Least Squares   F-statistic:                     9715.\n",
       "Date:                Thu, 15 Mar 2018   Prob (F-statistic):               0.00\n",
       "Time:                        17:32:54   Log-Likelihood:             3.5623e+05\n",
       "No. Observations:              199364   AIC:                        -7.125e+05\n",
       "Df Residuals:                  199362   BIC:                        -7.124e+05\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.2040      0.002     99.309      0.000       0.200       0.208\n",
       "V10           -0.3976      0.004    -98.566      0.000      -0.406      -0.390\n",
       "==============================================================================\n",
       "Omnibus:                   455375.505   Durbin-Watson:                   0.095\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       2328850286.992\n",
       "Skew:                          22.492   Prob(JB):                         0.00\n",
       "Kurtosis:                     530.570   Cond. No.                         56.0\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_train_V_10 = sm.add_constant(X_train[\"V10\"])\n",
    "X_test_V_10 = sm.add_constant(X_test[\"V10\"])\n",
    "\n",
    "ols = OLS(endog=y_train, exog=X_train_V_10).fit()\n",
    "ols.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s plot our model… "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "_uuid": "4bcff2e425e371b8c29d1a391f0cbfbe182249d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1171a588>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11721eb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(x=X_train[\"V10\"], y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91671     0.002482\n",
       "52584     0.024402\n",
       "177195    0.024575\n",
       "6899      0.060896\n",
       "8296      0.107374\n",
       "192529    0.047548\n",
       "89190     0.034561\n",
       "221041    0.027033\n",
       "42674     0.097080\n",
       "281674    0.009042\n",
       "150601    0.113126\n",
       "6641      0.034180\n",
       "68067     0.002965\n",
       "142405    0.073684\n",
       "150644    0.100547\n",
       "151008    0.184266\n",
       "6609      0.052737\n",
       "144754    0.018759\n",
       "31002     0.063451\n",
       "154718    0.062071\n",
       "178208    0.041970\n",
       "191544    0.033871\n",
       "83053     0.028359\n",
       "76929     0.050886\n",
       "154670    0.075723\n",
       "124176    0.020086\n",
       "9252      0.109807\n",
       "42936     0.106181\n",
       "144104    0.051057\n",
       "8615      0.110274\n",
       "203324    0.020418\n",
       "208651    0.044346\n",
       "249167    0.038271\n",
       "18466     0.017237\n",
       "154633    0.037626\n",
       "213092   -0.031437\n",
       "141259    0.070325\n",
       "11343     0.111548\n",
       "20198    -0.024968\n",
       "143335    0.071971\n",
       "244004    0.020859\n",
       "204503    0.033331\n",
       "223618    0.037937\n",
       "234574    0.053441\n",
       "10568     0.097388\n",
       "15736     0.071185\n",
       "197586    0.020226\n",
       "255556    0.034336\n",
       "63421     0.053119\n",
       "244333    0.020151\n",
       "623       0.008629\n",
       "18773     0.039512\n",
       "226877    0.059725\n",
       "10204    -0.007134\n",
       "154693    0.060762\n",
       "42887     0.109292\n",
       "221018    0.042351\n",
       "230076    0.041644\n",
       "79835     0.027042\n",
       "72757    -0.006582\n",
       "123301    0.022663\n",
       "151011    0.142755\n",
       "223572    0.048243\n",
       "255403    0.026944\n",
       "149357    0.035925\n",
       "15166     0.076106\n",
       "76555     0.065478\n",
       "41569     0.026833\n",
       "6329      0.021866\n",
       "43204     0.108760\n",
       "6717      0.063062\n",
       "102443    0.043298\n",
       "249607    0.034878\n",
       "150680    0.129775\n",
       "154371    0.192831\n",
       "6331      0.052638\n",
       "149869    0.035425\n",
       "274382   -0.020390\n",
       "16415     0.030243\n",
       "93788     0.003327\n",
       "15751     0.070614\n",
       "6774      0.046077\n",
       "245347   -0.008802\n",
       "8312      0.044125\n",
       "68522     0.027205\n",
       "10891     0.108180\n",
       "43428     0.117816\n",
       "235644    0.044311\n",
       "254395   -0.007168\n",
       "167305   -0.002932\n",
       "215984    0.043795\n",
       "30496     0.066178\n",
       "42856     0.107331\n",
       "14197     0.077607\n",
       "123238    0.019012\n",
       "86155     0.020662\n",
       "42958     0.122475\n",
       "252774    0.047254\n",
       "33276     0.008271\n",
       "234632    0.028077\n",
       "30314     0.051650\n",
       "251881   -0.000153\n",
       "76609     0.066432\n",
       "151196    0.004672\n",
       "263080    0.009964\n",
       "150677    0.110349\n",
       "235616    0.017142\n",
       "69980     0.026384\n",
       "61787     0.025528\n",
       "143336    0.071971\n",
       "157868    0.044580\n",
       "101509   -0.002528\n",
       "234705    0.029860\n",
       "150687    0.121296\n",
       "64411     0.051065\n",
       "47802     0.042709\n",
       "59539     0.022262\n",
       "83297     0.029917\n",
       "167184   -0.002001\n",
       "56703     0.006549\n",
       "14338     0.004773\n",
       "149577    0.029506\n",
       "274475    0.022435\n",
       "154960    0.038866\n",
       "83417     0.028490\n",
       "150668    0.124517\n",
       "111690    0.040268\n",
       "192687    0.013491\n",
       "154676    0.057733\n",
       "123201    0.019462\n",
       "223366    0.024213\n",
       "154720    0.058202\n",
       "10630     0.098701\n",
       "250761    0.044989\n",
       "17366     0.067050\n",
       "6108      0.041234\n",
       "44270     0.152049\n",
       "150654    0.093727\n",
       "143333    0.070917\n",
       "176049    0.014331\n",
       "84543     0.030939\n",
       "63634     0.052203\n",
       "99506     0.034235\n",
       "154234    0.164924\n",
       "102441    0.043298\n",
       "64460     0.050495\n",
       "6472      0.034275\n",
       "201098    0.033801\n",
       "67583     0.015438\n",
       "241728    0.014093\n",
       "176243   -0.001313\n",
       "117194    0.004184\n",
       "1545      0.003136\n",
       "263680    0.006087\n",
       "175644   -0.005134\n",
       "40674     0.002316\n",
       "256349    0.006458\n",
       "33614     0.005237\n",
       "125657   -0.004444\n",
       "240682    0.003445\n",
       "165415    0.004579\n",
       "33529    -0.004900\n",
       "195445    0.003804\n",
       "54460     0.002171\n",
       "90636     0.002185\n",
       "158769   -0.003740\n",
       "223996   -0.006868\n",
       "21740     0.002046\n",
       "223768    0.010550\n",
       "127904    0.013677\n",
       "141432    0.003180\n",
       "183709    0.013154\n",
       "32198     0.006024\n",
       "33921     0.005607\n",
       "170297    0.018791\n",
       "180361    0.001471\n",
       "149217    0.015221\n",
       "103279   -0.001078\n",
       "92193    -0.007614\n",
       "171920   -0.007377\n",
       "95230     0.000828\n",
       "230192   -0.005925\n",
       "10330     0.011617\n",
       "63715    -0.016696\n",
       "50311    -0.004432\n",
       "64190     0.002852\n",
       "255      -0.012278\n",
       "133845   -0.001098\n",
       "200939   -0.004845\n",
       "115520    0.000449\n",
       "105617    0.004578\n",
       "219159   -0.004684\n",
       "190994   -0.002886\n",
       "13839     0.003549\n",
       "40023     0.002804\n",
       "23808     0.003253\n",
       "264997   -0.001932\n",
       "117686    0.000534\n",
       "132451    0.004610\n",
       "154928    0.011419\n",
       "182505   -0.017822\n",
       "185622   -0.010501\n",
       "273124   -0.000043\n",
       "166107   -0.005455\n",
       "167894   -0.002272\n",
       "257665    0.004071\n",
       "140030   -0.003107\n",
       "167216    0.007792\n",
       "202143   -0.004210\n",
       "122128   -0.010460\n",
       "5361      0.000631\n",
       "273181    0.004094\n",
       "32511    -0.007490\n",
       "11798     0.005835\n",
       "239248    0.001314\n",
       "199749   -0.004843\n",
       "43354     0.000941\n",
       "2875      0.009710\n",
       "277574    0.007730\n",
       "195666    0.007642\n",
       "156533   -0.020442\n",
       "9128      0.000688\n",
       "189523   -0.002000\n",
       "103439    0.013105\n",
       "128897   -0.009082\n",
       "42285     0.000946\n",
       "101745    0.002847\n",
       "258202    0.003472\n",
       "235849    0.008196\n",
       "51014     0.019053\n",
       "80286     0.008504\n",
       "216543    0.012162\n",
       "139967    0.002496\n",
       "36681    -0.040221\n",
       "146707    0.005616\n",
       "206001    0.002883\n",
       "103804    0.001483\n",
       "162529   -0.003880\n",
       "93011     0.002570\n",
       "104595   -0.003202\n",
       "216581   -0.006460\n",
       "151498    0.011026\n",
       "120772    0.003546\n",
       "43151     0.005109\n",
       "141067    0.000947\n",
       "21232    -0.005737\n",
       "115472   -0.003378\n",
       "53952    -0.004437\n",
       "28750    -0.000117\n",
       "281254    0.002370\n",
       "231310    0.000139\n",
       "240280   -0.007211\n",
       "228072   -0.007033\n",
       "64766     0.007989\n",
       "12394    -0.000619\n",
       "189865    0.000964\n",
       "90072    -0.009775\n",
       "35264    -0.004159\n",
       "108631    0.006309\n",
       "118567   -0.002322\n",
       "237503    0.010342\n",
       "277026    0.011191\n",
       "39358     0.019274\n",
       "189823   -0.000795\n",
       "64634     0.007014\n",
       "200807   -0.015527\n",
       "181061   -0.005145\n",
       "26556     0.004477\n",
       "76335     0.001075\n",
       "353      -0.009482\n",
       "6316      0.011322\n",
       "125057   -0.003714\n",
       "185650    0.005762\n",
       "213064    0.011365\n",
       "183997   -0.000676\n",
       "175500   -0.012991\n",
       "8771      0.007160\n",
       "174043   -0.010873\n",
       "110162    0.014574\n",
       "103305    0.002305\n",
       "204851    0.004003\n",
       "86244     0.004366\n",
       "235366   -0.000724\n",
       "49829     0.009153\n",
       "239757    0.008144\n",
       "231560    0.010244\n",
       "100687   -0.003817\n",
       "191372   -0.004683\n",
       "271906   -0.008909\n",
       "261004    0.012061\n",
       "192559   -0.001553\n",
       "147859    0.009430\n",
       "264044    0.005725\n",
       "28515     0.009148\n",
       "246580    0.003134\n",
       "45695     0.008427\n",
       "31490     0.001039\n",
       "272845    0.005266\n",
       "198847   -0.001341\n",
       "172491   -0.008734\n",
       "72014     0.009020\n",
       "44954    -0.004432\n",
       "20014    -0.002924\n",
       "111190    0.010091\n",
       "195266   -0.013780\n",
       "163380    0.001093\n",
       "269885    0.004602\n",
       "46997     0.000702\n",
       "3128     -0.000480\n",
       "80670    -0.004894\n",
       "165193    0.006674\n",
       "129749    0.014449\n",
       "233263    0.001758\n",
       "162895   -0.009125\n",
       "81810     0.002381\n",
       "221850    0.000674\n",
       "281219    0.003350\n",
       "197289    0.011565\n",
       "246618   -0.006205\n",
       "212446    0.010705\n",
       "255992    0.003133\n",
       "260610    0.006883\n",
       "28247     0.004915\n",
       "67420     0.002890\n",
       "209200    0.010566\n",
       "188695    0.010569\n",
       "133668    0.002954\n",
       "67952     0.004200\n",
       "165651   -0.000384\n",
       "108849    0.008611\n",
       "47589     0.000660\n",
       "49561     0.006662\n",
       "117664    0.000803\n",
       "86275     0.004496\n",
       "263394    0.006446\n",
       "85603     0.004774\n",
       "21992     0.006476\n",
       "270154   -0.010453\n",
       "250432   -0.010295\n",
       "256974    0.007725\n",
       "38555     0.006094\n",
       "137714    0.004368\n",
       "187709    0.011251\n",
       "77978    -0.003723\n",
       "104661    0.002364\n",
       "177158   -0.003747\n",
       "269804    0.009599\n",
       "106240    0.003449\n",
       "84944    -0.002464\n",
       "262434   -0.005431\n",
       "6265     -0.009584\n",
       "102282    0.001705\n",
       "12617     0.013720\n",
       "45987    -0.001563\n",
       "235388   -0.000160\n",
       "132035    0.002026\n",
       "146115    0.009854\n",
       "206451    0.016531\n",
       "217910   -0.011102\n",
       "93332    -0.008798\n",
       "251277   -0.012487\n",
       "217626   -0.001562\n",
       "159130    0.005998\n",
       "125254    0.005881\n",
       "104635   -0.001946\n",
       "123083    0.001224\n",
       "19440    -0.030583\n",
       "127968   -0.000765\n",
       "263844    0.003305\n",
       "15859    -0.006130\n",
       "127176   -0.004536\n",
       "177823   -0.008861\n",
       "16300     0.002949\n",
       "240791    0.007636\n",
       "146136   -0.006877\n",
       "217987   -0.002345\n",
       "16121    -0.004580\n",
       "94777    -0.003239\n",
       "132324   -0.005907\n",
       "152805    0.005213\n",
       "179761   -0.007230\n",
       "218955    0.002940\n",
       "171090    0.000732\n",
       "66750     0.001838\n",
       "267141    0.001146\n",
       "48727    -0.015005\n",
       "23334     0.001283\n",
       "58611     0.004303\n",
       "134208   -0.004272\n",
       "229096    0.000111\n",
       "12059    -0.001809\n",
       "21264     0.019351\n",
       "48066    -0.003514\n",
       "142414    0.010648\n",
       "56688    -0.002757\n",
       "2750      0.002628\n",
       "10248     0.007049\n",
       "223077    0.003100\n",
       "267111    0.009839\n",
       "71716    -0.004022\n",
       "4778      0.010021\n",
       "138360    0.003409\n",
       "276152   -0.003297\n",
       "170122   -0.000985\n",
       "214305    0.004510\n",
       "136467    0.011600\n",
       "124138   -0.009388\n",
       "11888     0.000452\n",
       "276921   -0.011506\n",
       "4248     -0.000967\n",
       "178011    0.011528\n",
       "10196     0.000018\n",
       "130794    0.010710\n",
       "234703    0.010701\n",
       "12926     0.012192\n",
       "56161     0.000918\n",
       "148640    0.004097\n",
       "187410   -0.010718\n",
       "34456     0.002717\n",
       "147232    0.001435\n",
       "223306    0.003967\n",
       "129657    0.001287\n",
       "172154    0.007155\n",
       "231732    0.003667\n",
       "46844    -0.004065\n",
       "180265    0.010122\n",
       "127937   -0.073727\n",
       "216447   -0.002961\n",
       "188217    0.006088\n",
       "152759    0.010372\n",
       "263483   -0.010894\n",
       "125282   -0.004480\n",
       "145375    0.002953\n",
       "135944    0.003961\n",
       "72904     0.002848\n",
       "8343      0.000004\n",
       "124804    0.003062\n",
       "69711     0.006888\n",
       "138908    0.001740\n",
       "86453     0.001711\n",
       "248549    0.015508\n",
       "20895    -0.008868\n",
       "282519    0.000654\n",
       "178731    0.004338\n",
       "12364     0.007789\n",
       "270007    0.002168\n",
       "248506    0.005118\n",
       "146349    0.008259\n",
       "2718      0.002162\n",
       "20499     0.002780\n",
       "253692   -0.010573\n",
       "237789    0.010286\n",
       "45919    -0.001899\n",
       "34742     0.002541\n",
       "18905    -0.001419\n",
       "45849     0.011499\n",
       "73317     0.004740\n",
       "69659     0.006139\n",
       "265099    0.001430\n",
       "70584     0.013877\n",
       "222806    0.006198\n",
       "14371     0.008646\n",
       "248864    0.003324\n",
       "143101   -0.009712\n",
       "53825     0.004767\n",
       "67715     0.002029\n",
       "248562    0.002335\n",
       "208119    0.000330\n",
       "23727     0.008631\n",
       "274233   -0.010468\n",
       "64863     0.008484\n",
       "248353    0.011333\n",
       "224700    0.000399\n",
       "94075     0.000924\n",
       "37366     0.001768\n",
       "30779     0.000607\n",
       "113980    0.010858\n",
       "176816   -0.001317\n",
       "235382    0.002015\n",
       "95838     0.006050\n",
       "121252    0.003279\n",
       "164400    0.005342\n",
       "104592    0.002197\n",
       "218204    0.002393\n",
       "68404    -0.003810\n",
       "172043    0.003559\n",
       "193412    0.008673\n",
       "207754    0.013945\n",
       "835      -0.000592\n",
       "160534   -0.004287\n",
       "107113    0.005201\n",
       "158780    0.005299\n",
       "257655    0.000429\n",
       "91004     0.004034\n",
       "254202    0.012143\n",
       "42198     0.000690\n",
       "174396    0.008233\n",
       "200129    0.012217\n",
       "29513    -0.010222\n",
       "            ...   \n",
       "60395     0.000308\n",
       "50074     0.001697\n",
       "174065    0.000605\n",
       "83912     0.002070\n",
       "1719     -0.008431\n",
       "174786    0.005163\n",
       "123617    0.010393\n",
       "247580   -0.002549\n",
       "16261     0.006680\n",
       "263765    0.001980\n",
       "152356    0.006575\n",
       "145860    0.008356\n",
       "169352    0.002764\n",
       "152436    0.003457\n",
       "173885   -0.006145\n",
       "21669    -0.009891\n",
       "121849   -0.003584\n",
       "172731   -0.011101\n",
       "117602   -0.000602\n",
       "165229   -0.000705\n",
       "197099   -0.001394\n",
       "200955    0.010072\n",
       "260323    0.016513\n",
       "210050   -0.007296\n",
       "260861    0.005609\n",
       "156994   -0.001260\n",
       "234795   -0.004172\n",
       "190754   -0.005947\n",
       "225114    0.003585\n",
       "124607    0.000670\n",
       "17993     0.011838\n",
       "176557   -0.005146\n",
       "127911   -0.006301\n",
       "249605   -0.005734\n",
       "80772     0.002315\n",
       "68396     0.002814\n",
       "197123   -0.008646\n",
       "159929    0.002229\n",
       "46780    -0.005464\n",
       "147284    0.005000\n",
       "96702     0.004262\n",
       "21513    -0.001025\n",
       "213307    0.000731\n",
       "151996    0.011716\n",
       "38797     0.008515\n",
       "124012    0.002418\n",
       "237401    0.004449\n",
       "198144    0.006379\n",
       "15864     0.001758\n",
       "257386   -0.004782\n",
       "185878    0.010659\n",
       "163847    0.007987\n",
       "104196    0.003850\n",
       "149560   -0.004867\n",
       "181699   -0.005674\n",
       "485       0.000800\n",
       "99092     0.002751\n",
       "122158   -0.003497\n",
       "251980    0.016962\n",
       "143738    0.005979\n",
       "61653     0.001401\n",
       "23741     0.001950\n",
       "123760   -0.006248\n",
       "25967    -0.003388\n",
       "225973   -0.002484\n",
       "17518    -0.010538\n",
       "272242   -0.010849\n",
       "225857    0.002957\n",
       "213889   -0.012135\n",
       "224693    0.004657\n",
       "43791    -0.023053\n",
       "98089     0.001348\n",
       "112231   -0.001743\n",
       "239782    0.003042\n",
       "29535     0.005447\n",
       "385       0.006463\n",
       "79630     0.006420\n",
       "121068    0.004010\n",
       "233634    0.005233\n",
       "69055     0.013654\n",
       "99021    -0.009550\n",
       "203302   -0.001457\n",
       "256122    0.001894\n",
       "134817    0.004424\n",
       "282216   -0.005599\n",
       "43508    -0.003188\n",
       "92855     0.004597\n",
       "13346     0.006040\n",
       "9718      0.009371\n",
       "93258     0.005667\n",
       "98695    -0.006634\n",
       "231893    0.006109\n",
       "84000     0.002020\n",
       "117807    0.001118\n",
       "131638   -0.003015\n",
       "91977    -0.002710\n",
       "219207   -0.002081\n",
       "245809   -0.004062\n",
       "51698    -0.003367\n",
       "271205   -0.000512\n",
       "61834    -0.000514\n",
       "164632    0.010155\n",
       "283873    0.003592\n",
       "211449    0.012793\n",
       "196388    0.001458\n",
       "212385    0.002998\n",
       "44174     0.012731\n",
       "213992   -0.002474\n",
       "69023    -0.003647\n",
       "92598    -0.000135\n",
       "265344    0.000727\n",
       "149627    0.004613\n",
       "141368   -0.005098\n",
       "10820     0.006272\n",
       "282677   -0.004920\n",
       "94981    -0.002225\n",
       "53647     0.007079\n",
       "246966    0.008288\n",
       "282605    0.001779\n",
       "251958    0.000213\n",
       "125941    0.004316\n",
       "184934    0.001278\n",
       "236120   -0.004801\n",
       "35834     0.001266\n",
       "189307    0.005032\n",
       "119383    0.004385\n",
       "151629   -0.002576\n",
       "238290   -0.006617\n",
       "58599     0.000763\n",
       "68339     0.005752\n",
       "135128    0.005031\n",
       "253756   -0.009471\n",
       "119860    0.002437\n",
       "273085    0.005423\n",
       "148728    0.002811\n",
       "228372    0.004945\n",
       "85833     0.003943\n",
       "212033    0.013497\n",
       "93840     0.014917\n",
       "83422     0.004033\n",
       "270960   -0.011987\n",
       "120179    0.005680\n",
       "14797     0.003871\n",
       "263941    0.001700\n",
       "197236   -0.000301\n",
       "182445   -0.000985\n",
       "123547   -0.008647\n",
       "283789   -0.003777\n",
       "211406   -0.009049\n",
       "233507    0.006296\n",
       "208544   -0.004485\n",
       "129255    0.000989\n",
       "71330     0.003598\n",
       "200786    0.007196\n",
       "260750    0.003363\n",
       "259538   -0.000676\n",
       "223125    0.008509\n",
       "10028     0.003884\n",
       "176881    0.004647\n",
       "16296     0.000400\n",
       "153203    0.001763\n",
       "213668   -0.001283\n",
       "32504    -0.011468\n",
       "114607   -0.003849\n",
       "153982    0.010696\n",
       "201565    0.007112\n",
       "151601    0.000876\n",
       "210747   -0.002054\n",
       "77277     0.002641\n",
       "112927   -0.000993\n",
       "4597      0.006067\n",
       "32959    -0.003418\n",
       "202320   -0.007742\n",
       "243947    0.008093\n",
       "102576    0.003309\n",
       "150092   -0.002776\n",
       "239177    0.001428\n",
       "249463    0.004397\n",
       "210457   -0.004658\n",
       "230021    0.007532\n",
       "154651   -0.009463\n",
       "157015   -0.001041\n",
       "263629    0.003166\n",
       "226127   -0.005668\n",
       "133646    0.015697\n",
       "44789     0.004150\n",
       "180862   -0.001735\n",
       "226804    0.009066\n",
       "26569    -0.001543\n",
       "131076    0.002530\n",
       "78143    -0.000168\n",
       "211068   -0.009094\n",
       "181674    0.005290\n",
       "257104   -0.005400\n",
       "180836    0.001979\n",
       "181324   -0.001214\n",
       "47507     0.012889\n",
       "164049    0.006016\n",
       "103630    0.001581\n",
       "146534    0.002890\n",
       "11800     0.003581\n",
       "231702   -0.009930\n",
       "188808    0.005990\n",
       "234380    0.009481\n",
       "240770    0.002036\n",
       "171590    0.002405\n",
       "234424    0.010827\n",
       "146409    0.002481\n",
       "189436    0.003507\n",
       "53894    -0.010148\n",
       "66705    -0.001415\n",
       "136549    0.004063\n",
       "231506    0.004129\n",
       "211243    0.002838\n",
       "202332    0.000171\n",
       "249172    0.008595\n",
       "22888     0.008448\n",
       "262577    0.001474\n",
       "166929   -0.004107\n",
       "119887    0.003179\n",
       "149826   -0.005067\n",
       "84846     0.005867\n",
       "134660    0.001303\n",
       "124221    0.002211\n",
       "215188   -0.010542\n",
       "217403    0.001028\n",
       "123378    0.006174\n",
       "146035    0.008608\n",
       "64254     0.001570\n",
       "113162    0.010538\n",
       "270005   -0.004093\n",
       "116470   -0.002793\n",
       "270404   -0.003927\n",
       "123054    0.002508\n",
       "134969   -0.011172\n",
       "92902    -0.009281\n",
       "28322     0.011099\n",
       "281474    0.008295\n",
       "207009    0.001100\n",
       "214523   -0.007828\n",
       "65175     0.004202\n",
       "261838    0.003727\n",
       "258244    0.008727\n",
       "109585   -0.001816\n",
       "185784   -0.005964\n",
       "93645     0.001379\n",
       "173969   -0.073021\n",
       "31647     0.005486\n",
       "231983    0.011146\n",
       "224059    0.012307\n",
       "280987    0.006337\n",
       "166986    0.003486\n",
       "240965    0.003193\n",
       "18300    -0.005536\n",
       "20293    -0.003445\n",
       "27011     0.003796\n",
       "165190   -0.007388\n",
       "248539   -0.010709\n",
       "65984    -0.004267\n",
       "73580    -0.004156\n",
       "93714     0.003246\n",
       "166846    0.014101\n",
       "68994     0.001355\n",
       "186598   -0.001646\n",
       "126480    0.017844\n",
       "62562    -0.001681\n",
       "5204     -0.000946\n",
       "106493    0.005780\n",
       "194323    0.002187\n",
       "271254    0.008784\n",
       "235443    0.000038\n",
       "152072    0.006465\n",
       "279493   -0.011299\n",
       "143513    0.010992\n",
       "251628    0.007659\n",
       "13147     0.002763\n",
       "41608     0.004706\n",
       "264420   -0.009738\n",
       "124213    0.014408\n",
       "283136    0.005023\n",
       "36481    -0.005816\n",
       "18075     0.000982\n",
       "198664    0.006205\n",
       "257037    0.006367\n",
       "116452   -0.002218\n",
       "260405    0.000287\n",
       "111671    0.001097\n",
       "273526    0.008733\n",
       "279095    0.001670\n",
       "274976   -0.006324\n",
       "157857    0.006744\n",
       "253370   -0.024576\n",
       "67816     0.000752\n",
       "89489     0.005280\n",
       "172172    0.003032\n",
       "250067   -0.005739\n",
       "149647   -0.001979\n",
       "26218     0.006109\n",
       "159233    0.002362\n",
       "108538   -0.003312\n",
       "229140    0.003318\n",
       "103059    0.005155\n",
       "25170    -0.001775\n",
       "14194     0.003695\n",
       "257034   -0.020123\n",
       "152261   -0.039699\n",
       "219157   -0.005523\n",
       "90897     0.009275\n",
       "40142     0.003697\n",
       "29540    -0.005072\n",
       "168227   -0.012447\n",
       "79587    -0.005002\n",
       "250445   -0.001975\n",
       "228794    0.010429\n",
       "159467    0.001410\n",
       "103152   -0.003565\n",
       "22490    -0.007718\n",
       "221415   -0.006149\n",
       "116127    0.005682\n",
       "82032     0.007371\n",
       "140778    0.002733\n",
       "81172     0.005876\n",
       "165425    0.002282\n",
       "83237     0.001743\n",
       "281010    0.001785\n",
       "253028    0.000367\n",
       "143798    0.008383\n",
       "241056    0.010200\n",
       "123254   -0.004419\n",
       "99702    -0.000716\n",
       "135078    0.001051\n",
       "2165      0.003050\n",
       "246839   -0.003007\n",
       "145106    0.002395\n",
       "223938   -0.012135\n",
       "61962     0.002672\n",
       "131816    0.010279\n",
       "109683   -0.010255\n",
       "174698   -0.011680\n",
       "93686     0.007667\n",
       "90453     0.003506\n",
       "107803    0.009757\n",
       "53953     0.006104\n",
       "211760    0.007599\n",
       "172234    0.014752\n",
       "42820    -0.005140\n",
       "67237     0.001983\n",
       "109970    0.001876\n",
       "280767    0.008992\n",
       "69451     0.010227\n",
       "85950     0.007742\n",
       "86436     0.001665\n",
       "3452      0.011236\n",
       "78038    -0.003125\n",
       "18747     0.000664\n",
       "262994    0.001090\n",
       "239205   -0.010789\n",
       "159417    0.001965\n",
       "73064    -0.000087\n",
       "78870     0.004277\n",
       "235816   -0.008875\n",
       "68044     0.001134\n",
       "166926    0.003970\n",
       "12877     0.014227\n",
       "87469     0.010742\n",
       "212688    0.000498\n",
       "264839   -0.033832\n",
       "143968    0.008231\n",
       "29408     0.002061\n",
       "156674    0.009337\n",
       "280456   -0.001188\n",
       "122301    0.003299\n",
       "259053    0.007265\n",
       "165980   -0.008532\n",
       "235135    0.005282\n",
       "234710    0.000549\n",
       "154911    0.013932\n",
       "44668     0.000356\n",
       "138205    0.002414\n",
       "214829   -0.000644\n",
       "240813    0.021758\n",
       "194574    0.003578\n",
       "195362    0.003570\n",
       "225153   -0.004073\n",
       "240651    0.005334\n",
       "47277     0.007040\n",
       "224371    0.012504\n",
       "106849    0.001690\n",
       "21383    -0.003269\n",
       "259414   -0.010507\n",
       "133708    0.009643\n",
       "97606     0.001617\n",
       "235275    0.003392\n",
       "47954    -0.005666\n",
       "18907    -0.007661\n",
       "205745   -0.000837\n",
       "39576    -0.002358\n",
       "124841   -0.022429\n",
       "277580   -0.004555\n",
       "204743    0.011167\n",
       "34387     0.011097\n",
       "221049    0.006985\n",
       "95323     0.004351\n",
       "212195   -0.005096\n",
       "218221   -0.000476\n",
       "255459    0.010249\n",
       "249547   -0.004890\n",
       "26666     0.007539\n",
       "177967    0.007848\n",
       "13090     0.013354\n",
       "48888     0.002200\n",
       "153558   -0.007423\n",
       "186236   -0.004422\n",
       "65109     0.010196\n",
       "147491    0.002114\n",
       "163424    0.006375\n",
       "46860     0.002016\n",
       "17079     0.004546\n",
       "266028    0.006517\n",
       "201336    0.001306\n",
       "211266    0.000152\n",
       "135383    0.005223\n",
       "60695     0.014025\n",
       "610      -0.012167\n",
       "224240   -0.014776\n",
       "47030    -0.005517\n",
       "107048   -0.007672\n",
       "218888   -0.003455\n",
       "188481    0.003115\n",
       "11953     0.017627\n",
       "20135     0.011951\n",
       "147545   -0.003673\n",
       "105513    0.002229\n",
       "204311    0.012418\n",
       "167349   -0.024594\n",
       "101822    0.002396\n",
       "213343   -0.003081\n",
       "102998    0.001582\n",
       "224885    0.006907\n",
       "14907     0.003412\n",
       "276693    0.000488\n",
       "118761    0.000996\n",
       "134821    0.003486\n",
       "111052   -0.003087\n",
       "237449    0.002891\n",
       "8478      0.005800\n",
       "164637   -0.000466\n",
       "233968    0.011802\n",
       "162307    0.002332\n",
       "42270    -0.000047\n",
       "49956     0.000259\n",
       "123466    0.004138\n",
       "179536   -0.005353\n",
       "39737     0.007502\n",
       "176568   -0.001878\n",
       "1971     -0.002324\n",
       "135325    0.001894\n",
       "46417     0.004298\n",
       "260019    0.005893\n",
       "122853    0.000960\n",
       "98403     0.001709\n",
       "273281    0.012592\n",
       "127042   -0.001126\n",
       "98849     0.009714\n",
       "114963   -0.000224\n",
       "24664    -0.009822\n",
       "71174     0.009400\n",
       "60659     0.007146\n",
       "227342    0.001999\n",
       "270532    0.003860\n",
       "37647     0.005524\n",
       "148890    0.008617\n",
       "38281     0.010119\n",
       "134430    0.005046\n",
       "220109    0.006297\n",
       "156569    0.009934\n",
       "233697    0.013094\n",
       "229419   -0.012814\n",
       "65148     0.001462\n",
       "51292     0.002173\n",
       "207548    0.001359\n",
       "194408    0.006146\n",
       "29468     0.002143\n",
       "148502    0.001509\n",
       "104540   -0.009136\n",
       "3920      0.012990\n",
       "61830     0.013697\n",
       "210678   -0.010372\n",
       "142758    0.002214\n",
       "184956    0.011033\n",
       "164358    0.000080\n",
       "11542     0.002359\n",
       "137060    0.002419\n",
       "70482     0.008608\n",
       "40550     0.002455\n",
       "104320    0.013655\n",
       "166689   -0.004416\n",
       "235190   -0.009550\n",
       "258501   -0.019516\n",
       "Length: 85443, dtype: float64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat_train = ols.predict(X_train_V_10)\n",
    "y_hat_test = ols.predict(X_test_V_10)\n",
    "y_hat_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice it is possible for us to convert the above values into a binary classification by the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "_uuid": "afbb66ca8519cca52d3623e9925de0d749bf5528",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Accuracy for Linear Regression:  0.9982745129511847\n",
      "Test Set Accuracy for Linear Regression:  0.9982678510820079\n"
     ]
    }
   ],
   "source": [
    "y_hat_train_0_1 = y_hat_train >.5\n",
    "y_hat_test_0_1 = y_hat_test >.5\n",
    "\n",
    "print(\"Training Set Accuracy for Linear Regression: \", accuracy_score(y_train, y_hat_train_0_1))\n",
    "print(\"Test Set Accuracy for Linear Regression: \", accuracy_score(y_test, y_hat_test_0_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "14281708fd78279135588217b36ffc93ab363da1"
   },
   "source": [
    "## 4. Using one single predictor to fit a Logistic Regression Model instead"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can instead fit a logistic regression model onto our data and see how things change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy for Logistic Regression:  0.9986707730583255\n",
      "Test Accuracy for Logistic Regression:  0.9987125920204113\n"
     ]
    }
   ],
   "source": [
    "logistic_mod = LogisticRegression(C=100, fit_intercept=True) #The C value here is a way to prevent regularization\n",
    "X_train_mul_wcons = sm.add_constant(X_train[\"V10\"])\n",
    "X_test_mul_wcons = sm.add_constant(X_test[\"V10\"])\n",
    "logistic_mod.fit(X_train_mul_wcons, y_train)\n",
    "\n",
    "y_hat_train_logistic_mod = logistic_mod.predict(X_train_mul_wcons)\n",
    "y_hat_test_logistic_mod = logistic_mod.predict(X_test_mul_wcons)\n",
    "\n",
    "print(\"Training Accuracy for Logistic Regression: \", accuracy_score(y_train, y_hat_train_logistic_mod))\n",
    "print(\"Test Accuracy for Logistic Regression: \", accuracy_score(y_test, y_hat_test_logistic_mod))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Using all predictor variables in a logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy for Logistic Regression:  0.9991773840813788\n",
      "Test accuracy for Logistic Regression:  0.9992860737567735\n"
     ]
    }
   ],
   "source": [
    "logistic_mod_all = LogisticRegression(C=100000, fit_intercept=True)\n",
    "X_train_mul_wcons = sm.add_constant(X_train)\n",
    "X_test_mul_wcons = sm.add_constant(X_test)\n",
    "\n",
    "lrmodel = logistic_mod_all.fit(X_train_mul_wcons, y_train)\n",
    "y_hat_train_logistic_mod_all = logistic_mod_all.predict(X_train_mul_wcons)\n",
    "y_hat_test_logistic_mod_all = logistic_mod_all.predict(X_test_mul_wcons)\n",
    "print(\"Training accuracy for Logistic Regression: \", accuracy_score(y_train, y_hat_train_logistic_mod_all))\n",
    "print(\"Test accuracy for Logistic Regression: \", accuracy_score(y_test, y_hat_test_logistic_mod_all))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Do we have binary logistic regression summary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-482a82d65197>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlrmodelsummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlrmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lrmodelsummary = lrmodel.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     85295\n",
      "          1       0.88      0.68      0.77       148\n",
      "\n",
      "avg / total       1.00      1.00      1.00     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate the accuracy measures\n",
    "predicted = np.round(y_hat_test_logistic_mod_all)\n",
    "expected = y_test\n",
    "print(metrics.classification_report(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85282</td>\n",
       "      <td>13</td>\n",
       "      <td>85295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>100</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>85330</td>\n",
       "      <td>113</td>\n",
       "      <td>85443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted      0    1    All\n",
       "Actual                      \n",
       "0          85282   13  85295\n",
       "1             48  100    148\n",
       "All        85330  113  85443"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the confusion matrix\n",
    "pd.crosstab(expected,predicted,margins=True, rownames=['Actual'], colnames=['Predicted'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Incorporating Bootstrapping in a Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea behind bootstrapping is to resample our data many times. For EACH time that we resample our data, we will fit the Logistic Regression model. Then for EACH resampling, we can find an associated confidence interval. \n",
    "\n",
    "Compared to traditional statistical confidence intervals, the bootstrap confidence intervals are free from empirical assumptions of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The code below helps us conduct a boostrap analysis and be able to obtain confidence interval estimates for each coefficient value!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31, 100)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = 100 # Number of iterations\n",
    "\n",
    "boot_coefs = np.zeros((X_train.shape[1]+1,B)) # Create empty storage array for later use\n",
    "\n",
    "for i in range(B):\n",
    "    # Sampling WITH replacement the indices of a resampled dataset\n",
    "    sample_index = np.random.choice(range(len(y_train)), size=len(y_train), replace=True)\n",
    "    X_train_samples = X_train_mul_wcons.values[sample_index]\n",
    "    y_train_samples = y_train[sample_index]\n",
    "    \n",
    "    logistic_mod_boot = LogisticRegression(C=100000, fit_intercept=True)\n",
    "    logistic_mod_boot.fit(X_train_samples, y_train_samples)\n",
    "    boot_coefs[:,i] = logistic_mod_boot.coef_\n",
    "\n",
    "boot_coefs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.61768439,  29.07024297,  29.53531299, ...,  42.61517494,\n",
       "         33.4880086 ,  29.29267811],\n",
       "       [  0.06474918,  -1.10034889,  -0.22672553, ...,  -0.64244893,\n",
       "         -1.1555187 ,  -0.55595314],\n",
       "       [  1.73580931,   9.18719898,   3.90356464, ...,  12.0651244 ,\n",
       "          8.65893011,   8.77648258],\n",
       "       ...,\n",
       "       [-39.81683201, -27.11433762, -46.35517502, ..., -48.66330954,\n",
       "        -52.73381479, -55.78308062],\n",
       "       [-17.67739219,  -9.09128379, -14.79207115, ..., -14.26817175,\n",
       "        -20.56993134, -18.15449215],\n",
       "       [ 27.25056406,  21.62667975,  18.65260629, ...,  21.99526853,\n",
       "         38.7380758 ,  33.50793904]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06474918, -1.10034889, -0.22672553, -0.70337602, -0.21806237,\n",
       "       -0.33078374, -0.7808378 , -0.46293902, -1.17205486, -0.51089218,\n",
       "       -0.45280299, -0.75357909, -0.73685097, -0.63086796, -0.69742575,\n",
       "       -0.3871633 , -0.51623636, -0.53762426, -0.40771114, -0.74094441,\n",
       "        0.09727066, -1.08273886, -0.42177591, -1.05557308,  0.55345043,\n",
       "       -1.37072168, -0.26797117, -1.04370959, -0.80787525, -0.13862455,\n",
       "       -0.34577687, -0.93749337, -1.24934046, -1.10914169, -0.16425098,\n",
       "       -1.00080665, -0.19484969, -0.01521422, -0.57768405,  0.0565753 ,\n",
       "       -0.73441608, -1.21788332, -0.60072617, -1.43352403, -0.47343425,\n",
       "       -0.40022692, -0.04437486, -1.01829091, -0.98148098, -0.38153194,\n",
       "       -1.36730381, -1.38745962, -0.36237083, -1.16451913, -1.11920764,\n",
       "       -1.23264159, -0.9812173 , -1.03941642, -1.28744566, -0.79144466,\n",
       "        0.39290682, -0.94322668,  0.06237527, -0.66576866, -0.38104219,\n",
       "       -0.21173388, -1.09487787, -0.44833506, -0.49925673, -1.19563906,\n",
       "       -0.11114944, -1.36568274, -0.81116301, -0.90297621, -0.44295809,\n",
       "        0.11977155, -0.62663867, -0.82298143, -0.30584952,  0.54401207,\n",
       "        0.32987601,  0.12548792, -0.79363943, -1.11518196,  0.15573956,\n",
       "       -0.1732428 , -0.48497705, -0.24868011, -0.81286358, -0.6382589 ,\n",
       "       -1.08192689, -0.92542655, -0.884559  , -1.0410105 , -0.04216704,\n",
       "       -0.59580893, -1.12194515, -0.64244893, -1.1555187 , -0.55595314])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  9.70093008,  -3.36585778,   3.06631091, -10.32614405,\n",
       "        10.45973019,   0.74835871,   2.76777039,  11.62864942,\n",
       "         2.78912549,   5.8325713 ,   9.93492254,  23.99151973,\n",
       "        -5.81985628,  -2.62176475,   9.86172368,   4.38428385,\n",
       "         1.17468701,   5.98662273,   3.40872753,  -2.81559142,\n",
       "        22.27304685,   0.14858675,  21.47941847,  -1.95506645,\n",
       "        -6.11326296,  -2.10648181,   2.25002587,  -1.5835139 ,\n",
       "        -0.42590208,   3.17621516,   5.78191192,   3.64784796,\n",
       "         7.06213005,  -2.27504592,  33.34970052,  -0.86636713,\n",
       "        12.58303921,  18.39074944,   9.32554777,  -4.67820183,\n",
       "         6.98893836,   4.54799744,  -8.78420336,  -5.92234284,\n",
       "         2.55752999,   5.54713806,  12.36209561,   7.70946781,\n",
       "        -9.52909754,  -5.83535503,  -1.68564612,   0.12877172,\n",
       "         0.44180568,   5.12561963,   6.68904807,   2.85480313,\n",
       "        27.94824223,  -0.4750544 ,   3.2135067 ,  14.45879192,\n",
       "        -6.62194107,  -0.04415321,  15.48056836,  16.68827204,\n",
       "        -7.59105797,   0.07987005,   2.1486221 ,  25.66647152,\n",
       "        -4.14492908,  -6.45450402,  10.80630937,  -4.6712666 ,\n",
       "        12.16066524,   0.19414139,  -0.23927557,  -8.00223281,\n",
       "        13.79456034,  23.54099135,   3.36538573,   3.78296392,\n",
       "         2.61434069,  -1.37686914,   5.9629809 ,  22.22242993,\n",
       "         6.85250674,   2.69149613,  14.03739701,   2.6569423 ,\n",
       "         6.0572095 ,  -3.31385555,   6.62249083,   7.17204921,\n",
       "        -4.47190172,  19.69309072, -12.82383959,  17.2093395 ,\n",
       "         2.76885807, -11.9398686 ,  -0.90260339,   6.18920529])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.73580931,  9.18719898,  3.90356464,  9.76443162,  5.50317364,\n",
       "        7.56248925,  5.53713637,  8.43775569,  6.36401038,  7.06163472,\n",
       "        0.73873853,  9.39952843, 12.98553957,  3.12390998,  6.04041966,\n",
       "        7.05668969,  8.81127269,  5.76058255,  7.00296524,  5.50567711,\n",
       "        0.20603141,  7.39352189,  2.85966288, 13.39908218,  8.31718771,\n",
       "       12.78744931,  8.69620639,  8.26626146, 13.26969523,  3.52419162,\n",
       "        5.89436583,  9.08262673, 11.54186914,  9.57417316, -1.14711339,\n",
       "        7.74563938,  6.13969574,  4.3019087 ,  5.59251354,  9.53183461,\n",
       "        8.7649757 , 11.1510794 ,  8.32711229,  8.43932496,  9.31977982,\n",
       "       10.40968417,  0.98320609,  8.25621114,  7.42056161, 12.33970931,\n",
       "        9.56503678,  6.59361757,  4.0041503 ,  4.03243989, 10.80917826,\n",
       "        6.52318729,  9.57786951,  6.52964905,  8.22170313,  6.83740795,\n",
       "       13.1079827 ,  6.62709477,  5.17249599,  7.93190146,  9.77942269,\n",
       "        7.52778731,  6.87338195,  2.46188135,  3.29223084, 13.92340212,\n",
       "        4.96760701, 11.85018468,  7.96091703,  7.91685683, 11.75102002,\n",
       "       12.67912204,  3.4960489 ,  4.59627896,  3.78764529,  9.35360872,\n",
       "        1.65754039,  6.74559682,  2.39584906,  7.33184692,  3.97399313,\n",
       "        4.9595782 ,  2.45328887,  7.39469597,  5.35692314,  8.86315817,\n",
       "        6.02094313,  6.03779037,  4.87732024,  7.16418305,  4.9470856 ,\n",
       "        4.04544438, 11.60297797, 12.0651244 ,  8.65893011,  8.77648258])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 18.61768439,  29.07024297,  29.53531299,  47.88742859,\n",
       "        17.33654279,  26.74287282,  28.4535274 ,  20.54105729,\n",
       "        31.56238185,  27.12765929,  18.18437163,   2.35338119,\n",
       "        41.42037804,  31.50357005,  21.86852866,  19.48812977,\n",
       "        24.71916914,  30.03860798,  37.47787929,  40.07599539,\n",
       "         4.20756005,  38.61017506,   9.38464552,  33.65912972,\n",
       "        42.90244442,  30.5529726 ,  32.23546051,  28.91480992,\n",
       "        30.57067029,  31.06813752,  24.77320566,  30.56237804,\n",
       "        26.73900619,  34.43976618, -24.14517636,  32.54516138,\n",
       "        22.35125174,  21.17368413,   5.81574678,  38.70844372,\n",
       "        39.06654861,  22.06915433,  39.49883581,  27.6433036 ,\n",
       "        35.6077628 ,  38.17243875,   5.50172649,  30.23390396,\n",
       "        43.11189491,  31.2990623 ,  34.35223886,  17.7045486 ,\n",
       "        27.62420755,  22.43982964,  24.48749093,  32.50515506,\n",
       "         0.09373064,  35.40723524,  24.9799348 ,  25.08296821,\n",
       "        34.77838229,  31.93305006,  14.21573767,  10.28909227,\n",
       "        42.94320323,  31.58470085,  26.28268463,  13.44569835,\n",
       "        29.58965756,  31.00461424,  17.32712798,  46.22135531,\n",
       "        19.77111191,  29.9960366 ,  33.27518557,  36.44649006,\n",
       "         0.96975539,   9.36042557,  22.48665824,  33.86764128,\n",
       "        21.08081394,  35.52469765,  17.06171328,  16.36948668,\n",
       "        18.57223666,  29.63989073,  18.2688263 ,  31.55995518,\n",
       "        22.55998346,  33.88524277,  23.13690614,  21.65032007,\n",
       "        30.86388124,  14.0782936 ,  43.09665412,  13.1770863 ,\n",
       "        34.00031387,  42.61517494,  33.4880086 ,  29.29267811])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: The coef_ of 'Time' feature is so large, are they really this positive related?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.25056406, 21.62667975, 18.65260629, 30.18447161, 27.10659888,\n",
       "        7.91029167, 25.92035708, 42.35514793, 28.36283152, 33.78271652,\n",
       "       19.55411845, 73.87645797, 30.24089529, 14.68867482, 20.99472541,\n",
       "       30.01903365, 39.27558375, 16.053523  , 27.85793625, 19.39935324,\n",
       "        8.10850459, 24.57655272, 24.12472452, 39.42771646, 25.69350779,\n",
       "       29.6132445 , 36.11557033, 14.5094762 , 42.39179072, 19.50189474,\n",
       "       35.49755664, 26.72895228, 36.92220473, 38.55830192, 34.5552489 ,\n",
       "       27.32371812, 39.91586504, 54.91547382, 29.32264903, 23.93696485,\n",
       "       45.22755176, 49.16686214, 17.72172124, 13.98799291, 35.99837481,\n",
       "       35.94542089, 23.85297118, 38.45625242, 12.37332346, 30.87285113,\n",
       "       23.5373769 , 17.12038959, 23.2689138 , 12.63838459, 50.27418374,\n",
       "       17.16942354, 54.77977798, 26.26711169, 14.71312784, 23.2325718 ,\n",
       "       21.82409002, 22.78309272, 32.26406538, 61.96729964, 30.85800284,\n",
       "       21.5030081 , 26.86314996, 27.02897515,  4.77596951, 26.10465567,\n",
       "       41.77356582, 34.10690909, 45.3577709 , 25.5939424 , 34.95736711,\n",
       "       28.59820914, 31.55371332, 28.47625035, 27.58288631, 41.15838454,\n",
       "       14.64237559, 34.62751093, 31.31129047, 63.77020668, 24.2826015 ,\n",
       "       29.85589042, 24.51871341, 35.13691556, 31.93651486, 18.63259765,\n",
       "       23.24836381, 31.80413911, 13.53480333, 45.60345331, 15.29399417,\n",
       "       35.32439839, 32.81711268, 21.99526853, 38.7380758 , 33.50793904])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-17.67739219,  -9.09128379, -14.79207115, -22.80143226,\n",
       "       -20.14600443, -13.22660566, -21.45461641, -12.93116089,\n",
       "       -16.22725268, -16.44438378,  -7.7254425 ,  -7.81898202,\n",
       "       -13.54743578,  -7.33123464, -22.69196519, -10.77114823,\n",
       "       -11.25481325, -19.83605241, -16.00047345, -21.90098634,\n",
       "       -13.80276415, -20.33768189, -10.79391065,  -9.67728386,\n",
       "       -16.84559065, -17.82435442, -24.07236707,  -7.71268991,\n",
       "        -6.45414406,  -9.95111781, -11.43738377, -24.63545597,\n",
       "       -19.41097952, -15.51007537,   0.12557662, -19.10391335,\n",
       "       -10.23034932, -15.6217123 ,  -8.66393142,  -9.84113222,\n",
       "       -26.23760615,  -4.97339077, -18.15581966, -18.37131613,\n",
       "       -17.84059042, -15.26998523,  -7.45680602, -20.53482259,\n",
       "       -16.9088321 , -16.42118838, -14.98440351, -11.37112865,\n",
       "       -10.53173145,  -8.88712424,  -7.002806  , -16.56302196,\n",
       "       -18.57026948, -21.26313476, -22.07745871, -17.91597208,\n",
       "       -10.4863878 , -10.18402083, -11.21715099,   0.98917845,\n",
       "       -22.48800976, -19.4403925 , -13.43255417, -22.7995002 ,\n",
       "       -19.11862157, -15.0067244 , -13.17347763, -24.33044642,\n",
       "       -13.77825028,  -9.35629881, -28.07821414, -19.10781915,\n",
       "       -15.10988598, -11.39881964,  -8.88487036, -12.55798186,\n",
       "        -5.09641696, -12.10665369, -11.73952371, -15.01266052,\n",
       "       -20.22924897, -18.6599396 , -20.49508964, -27.47291737,\n",
       "       -10.85135686, -15.76341793,  -6.93250912, -10.95086204,\n",
       "        -8.80701193,  -8.6062742 , -12.47552942, -15.21354191,\n",
       "        -8.63106264, -14.26817175, -20.56993134, -18.15449215])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boot_coefs[29]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to find the **95 percent** confidence interval, we can use the `np.percentile` function to find the datapoint that corresponds to the upper and lower bounds. As an example, we have the upper datapoint for the 95% confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_upper = np.percentile(boot_coefs, 97.5, axis=1)\n",
    "ci_lower = np.percentile(boot_coefs, 2.5, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant coefficents at 5pct level = 12 / 30\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Time'],\n",
       " ['V2'],\n",
       " ['V5'],\n",
       " ['V9'],\n",
       " ['V11'],\n",
       " ['V14'],\n",
       " ['V15'],\n",
       " ['V21'],\n",
       " ['V22'],\n",
       " ['V23'],\n",
       " ['V28'],\n",
       " ['Amount']]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ct significant predictors\n",
    "sig_b_ct = 0\n",
    "\n",
    "# if ci contains 0, then insignificant\n",
    "significantVars = []  \n",
    "for i in range((len(ci_upper)-1)):\n",
    "    if ci_upper[i]<0 or ci_lower[i]>0:\n",
    "        sig_b_ct += 1\n",
    "        significantVars.append([X_train.columns[i]])\n",
    "\n",
    "print(\"Significant coefficents at 5pct level = %i / %i\" % (sig_b_ct, X_train_np.shape[1]))\n",
    "significantVars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Quesetion: If using only significant features to build logistic regression, would the results be better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Draw ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
